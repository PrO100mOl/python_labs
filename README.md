# –ø—Ä–æ—Å—Ç–æ–º–æ–ª —É–Ω–æ

## –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 1

### –ó–∞–¥–∞–Ω–∏–µ 1
```python
–∏–º—è = str(input("–ò–º—è:"))
–≤–æ–∑—Ä–∞—Å—Ç = int(input("–í–æ–∑—Ä–∞—Å—Ç:"))
print(f"–ü—Ä–∏–≤–µ—Ç, {–∏–º—è}! –ß–µ—Ä–µ–∑ –≥–æ–¥ —Ç–µ–±–µ –±—É–¥–µ—Ç {–≤–æ–∑—Ä–∞—Å—Ç+1}.")
```

### –ó–∞–¥–∞–Ω–∏–µ 2
```python
–∏–º—è = float(input("a:").replace(",","."))
–≤–æ–∑—Ä–∞—Å—Ç = float(input("b:").replace(",","."))
print(f"sum={–∏–º—è+–≤–æ–∑—Ä–∞—Å—Ç}; avg={round((–∏–º—è+–≤–æ–∑—Ä–∞—Å—Ç)/2,2)}")
```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 1](./images/lab01/02_sum_avg.png)


### –ó–∞–¥–∞–Ω–∏–µ 3
```python
price= int(input("price="))
discount=int(input("discount="))
vat=int(input("vat="))
base = price * (1 - discount/100)
vat_amount = base * (vat/100)
total = base + vat_amount
print(f"–ë–∞–∑–∞ –ø–æ—Å–ª–µ —Å–∫–∏–¥–∫–∏: {base} ‚ÇΩ"
      f"\n–ù–î–°:               {vat_amount} ‚ÇΩ"
      f"\n–ò—Ç–æ–≥–æ –∫ –æ–ø–ª–∞—Ç–µ:    {total} ‚ÇΩ")
```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 1](./images/lab01/03_discount_vat.png)


### –ó–∞–¥–∞–Ω–∏–µ 4
```python
–ú–∏–Ω—É—Ç—ã=int(input("–ú–∏–Ω—É—Ç—ã: "))
print(–ú–∏–Ω—É—Ç—ã//60,":",–ú–∏–Ω—É—Ç—ã%60,sep="")
```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 1](./images/lab01/04_minutes_to_hhmm.png)


### –ó–∞–¥–∞–Ω–∏–µ 5
```python
f =str(input("–§–ò–û:"))
g = f.split()
h = ""
for i in g:
    h+=i[0]
j = f.split(" ")
k= 0
jj=0
for i in j:
    if len(i)!=0:
        k+=1
        jj+=len(i)
print(f"–ò–Ω–∏—Ü–∏–∞–ª—ã: {h}."
      f"\n–î–ª–∏–Ω–∞ (—Å–∏–º–≤–æ–ª–æ–≤): {jj+2}")

```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 1](./images/lab01/05_initials_and_len.py.png)


### –ó–∞–¥–∞–Ω–∏–µ 6
```python
f = int(input())
q,w=0,0
for i in range(f):
    _,_,_,g = input().split()
    if g == "True":
        q+=1
    else:
        w+=1
print(q,w)
```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 1](./images/lab01/06.png)


### –ó–∞–¥–∞–Ω–∏–µ 7
```python
i = str(input())
q,w=0,0
for t in range(len(i)):
    if i[t].upper() == i[t]:
        q = t
        break

for t in range(len(i)):
    if i[t] in ['0',"1","2","3","4","5",'6',"7","8","9"]:
        w = t+1
        break
print(i[q:len(i):w-q])
```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 1](./images/lab01/07.png)

## –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 2

### –ó–∞–¥–∞–Ω–∏–µ 1
```python
def min_max(nums: list[float | int]) -> tuple[float | int, float | int]:
    if len(nums) == 0:
        return "ValueError"
    return(min(nums),max(nums))
# –í–µ—Ä–Ω—É—Ç—å –∫–æ—Ä—Ç–µ–∂ (–º–∏–Ω–∏–º—É–º, –º–∞–∫—Å–∏–º—É–º). –ï—Å–ª–∏ —Å–ø–∏—Å–æ–∫ –ø—É—Å—Ç ‚Äî ValueError.

def unique_sorted(nums: list[float | int]) -> list[float | int]:
    nums.sort()
    return(list(set(nums)))
# –í–µ—Ä–Ω—É—Ç—å –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π (–ø–æ –≤–æ–∑—Ä–∞—Å—Ç–∞–Ω–∏—é).

def flatten(mat: list[list | tuple]) -> list:
    temp = []
    for x in mat:
        for y in x:
            if y == str(y):
                return "TypeError"
            temp.append(y)
    return(temp)
# ¬´–†–∞—Å–ø–ª—é—â–∏—Ç—å¬ª —Å–ø–∏—Å–æ–∫ —Å–ø–∏—Å–∫–æ–≤/–∫–æ—Ä—Ç–µ–∂–µ–π –≤ –æ–¥–∏–Ω —Å–ø–∏—Å–æ–∫ –ø–æ —Å—Ç—Ä–æ–∫–∞–º (row-major). –ï—Å–ª–∏ –≤—Å—Ç—Ä–µ—Ç–∏–ª–∞—Å—å —Å—Ç—Ä–æ–∫–∞/—ç–ª–µ–º–µ–Ω—Ç, –∫–æ—Ç–æ—Ä—ã–π –Ω–µ —è–≤–ª—è–µ—Ç—Å—è —Å–ø–∏—Å–∫–æ–º/–∫–æ—Ä—Ç–µ–∂–µ–º ‚Äî TypeError.

min_max

print(min_max([3, -1, 5, 5, 0]))# ‚Üí (-1, 5)
print(min_max([42]))# ‚Üí (42, 42)
print(min_max([-5, -2, -9]))# ‚Üí (-9, -2)
print(min_max([]))# ‚Üí ValueError
print(min_max([1.5, 2, 2.0, -3.1]))# ‚Üí (-3.1, 2)

unique_sorted

print(unique_sorted([3, 1, 2, 1, 3]))# ‚Üí [1, 2, 3]
print(unique_sorted([]))# ‚Üí []
print(unique_sorted([-1, -1, 0, 2, 2]))# ‚Üí [-1, 0, 2]
print(unique_sorted([1.0, 1, 2.5, 2.5, 0]))# ‚Üí [0, 1.0, 2.5] (–¥–æ–ø—É—Å–∫–∞–µ–º —Å–º–µ—à–µ–Ω–∏–µ int/float)

flatten

print(flatten([[1, 2], [3, 4]]))# ‚Üí [1, 2, 3, 4]
print(flatten([[1, 2], (3, 4, 5)]))# ‚Üí [1, 2, 3, 4, 5]
print(flatten([[1], [], [2, 3]]))# ‚Üí [1, 2, 3]
print(flatten([[1, 2], "ab"]))# ‚Üí TypeError (¬´—Å—Ç—Ä–æ–∫–∞ –Ω–µ —Å—Ç—Ä–æ–∫–∞ —Å—Ç—Ä–æ–∫ –º–∞—Ç—Ä–∏—Ü—ã¬ª)
```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 1](./images/lab02/01_arrays.png)

### –ó–∞–¥–∞–Ω–∏–µ 2
```python
def transpose(mat: list[list[float | int]]) -> list[list]:
    if mat == []:
        return []
    for i in range(1,len(mat)):
        if len(mat[i]) != len(mat[i-1]):
            return ("ValueError")

    strok = len(mat)
    tabs = len(mat[0])
    resmat = []
    for i in range(tabs):
        resmat.append([0]*strok)
    for x in range(strok):
        for y in range(tabs):
            resmat[y][x] = mat[x][y]
    return resmat
# –ü–æ–º–µ–Ω—è—Ç—å —Å—Ç—Ä–æ–∫–∏ –∏ —Å—Ç–æ–ª–±—Ü—ã –º–µ—Å—Ç–∞–º–∏. –ü—É—Å—Ç–∞—è –º–∞—Ç—Ä–∏—Ü–∞ [] ‚Üí [].
# –ï—Å–ª–∏ –º–∞—Ç—Ä–∏—Ü–∞ ¬´—Ä–≤–∞–Ω–∞—è¬ª (—Å—Ç—Ä–æ–∫–∏ —Ä–∞–∑–Ω–æ–π –¥–ª–∏–Ω—ã) ‚Äî ValueError.

def row_sums(mat: list[list[float | int]]) -> list[float]:
    for i in range(1,len(mat)):
        if len(mat[i]) != len(mat[i-1]):
            return ("ValueError")
    resmat = []
    o=0
    for i in mat:
        for t in i:
            o+=t
        resmat.append(o)
        o = 0
    return resmat
# –°—É–º–º–∞ –ø–æ –∫–∞–∂–¥–æ–π —Å—Ç—Ä–æ–∫–µ. –¢—Ä–µ–±—É–µ—Ç—Å—è –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–æ—Å—Ç—å (—Å–º. –≤—ã—à–µ).

def col_sums(mat: list[list[float | int]]) -> list[float]:
    for i in range(1,len(mat)):
        if len(mat[i]) != len(mat[i-1]):
            return ("ValueError")
    strok = len(mat)
    tabs = len(mat[0])
    resmat = []
    o = 0
    for i in range(tabs):
        for t in range(strok):
            o+=mat[t][i]
        resmat.append(o)
        o = 0
    return resmat
# –°—É–º–º–∞ –ø–æ –∫–∞–∂–¥–æ–º—É —Å—Ç–æ–ª–±—Ü—É. –¢—Ä–µ–±—É–µ—Ç—Å—è –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–æ—Å—Ç—å.

transpose

print(transpose([[1, 2, 3]])," ‚Üí [[1], [2], [3]]")
print(transpose([[1], [2], [3]])," ‚Üí [[1, 2, 3]]")
print(transpose([[1, 2], [3, 4]])," ‚Üí [[1, 3], [2, 4]]")
print(transpose([])," ‚Üí []")
print(transpose([[1, 2], [3]])," ‚Üí ValueError (—Ä–≤–∞–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞)")

row_sums

print(row_sums([[1, 2, 3], [4, 5, 6]])," ‚Üí [6, 15]")
print(row_sums([[-1, 1], [10, -10]])," ‚Üí [0, 0]")
print(row_sums([[0, 0], [0, 0]])," ‚Üí [0, 0]")
print(row_sums([[1, 2], [3]])," ‚Üí ValueError (—Ä–≤–∞–Ω–∞—è)")

col_sums

print(col_sums([[1, 2, 3], [4, 5, 6]])," ‚Üí [5, 7, 9]")
print(col_sums([[-1, 1], [10, -10]])," ‚Üí [9, -9]")
print(col_sums([[0, 0], [0, 0]])," ‚Üí [0, 0]")
print(col_sums([[1, 2], [3]])," ‚Üí ValueError (—Ä–≤–∞–Ω–∞—è)")

```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 1](./images/lab02/02_matrix.png)


### –ó–∞–¥–∞–Ω–∏–µ 3
```python
def format_record(rec: tuple[str, str, float]) -> str:
    for i in range(len(rec)-1):
        if len(rec[i])==0:
            return "ValueError"
    if type(rec[2]) != float:
        return "TypeError"
    
    fio = rec[0].split()

    if len(fio) == 1:
        return "ValueError"
    
    inic = str(fio[0][0].upper())+str(fio[0][1:])+" "
    for i in range(1, len(fio)):
        inic= inic+str(fio[i][0].upper())+"."
    
    round = "{:.2f}".format(rec[2])

    return f"{inic}, –≥—Ä. {rec[1]}, GPA {round}"


# –í–µ—Ä–Ω—É—Ç—å —Å—Ç—Ä–æ–∫—É –≤–∏–¥–∞:
# –ò–≤–∞–Ω–æ–≤ –ò.–ò., –≥—Ä. BIVT-25, GPA 4.60
# –ü—Ä–∞–≤–∏–ª–∞:

#     –§–ò–û –º–æ–∂–µ—Ç –±—ã—Ç—å ¬´–§–∞–º–∏–ª–∏—è –ò–º—è –û—Ç—á–µ—Å—Ç–≤–æ¬ª –∏–ª–∏ ¬´–§–∞–º–∏–ª–∏—è –ò–º—è¬ª ‚Äî –∏–Ω–∏—Ü–∏–∞–ª—ã —Ñ–æ—Ä–º–∏—Ä—É—é—Ç—Å—è –∏–∑ 1‚Äì2 –∏–º—ë–Ω (–≤ –≤–µ—Ä—Ö–Ω–µ–º —Ä–µ–≥–∏—Å—Ç—Ä–µ).
#     –õ–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –Ω—É–∂–Ω–æ —É–±—Ä–∞—Ç—å (strip, ¬´—Å—Ö–ª–æ–ø–Ω—É—Ç—å¬ª –≤–Ω—É—Ç—Ä–∏).
#     GPA –ø–µ—á–∞—Ç–∞–µ—Ç—Å—è —Å 2 –∑–Ω–∞–∫–∞–º–∏ (–æ–∫—Ä—É–≥–ª–µ–Ω–∏–µ –ø—Ä–∞–≤–∏–ª–∞–º–∏ Python).


print(format_record(("–ò–≤–∞–Ω–æ–≤ –ò–≤–∞–Ω –ò–≤–∞–Ω–æ–≤–∏—á", "BIVT-25", 4.6)), "‚Üí '–ò–≤–∞–Ω–æ–≤ –ò.–ò., –≥—Ä. BIVT-25, GPA 4.60'")
print(format_record(("–ü–µ—Ç—Ä–æ–≤ –ü—ë—Ç—Ä", "IKBO-12", 5.0)), "‚Üí '–ü–µ—Ç—Ä–æ–≤ –ü., –≥—Ä. IKBO-12, GPA 5.00'")
print(format_record(("–ü–µ—Ç—Ä–æ–≤ –ü—ë—Ç—Ä –ü–µ—Ç—Ä–æ–≤–∏—á", "IKBO-12", 5.0)), "‚Üí '–ü–µ—Ç—Ä–æ–≤ –ü.–ü., –≥—Ä. IKBO-12, GPA 5.00'")
print(format_record(("  —Å–∏–¥–æ—Ä–æ–≤–∞  –∞–Ω–Ω–∞   —Å–µ—Ä–≥–µ–µ–≤–Ω–∞ ", "ABB-01", 3.999)), "‚Üí '–°–∏–¥–æ—Ä–æ–≤–∞ –ê.–°., –≥—Ä. ABB-01, GPA 4.00'")
# –ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –∑–∞–ø–∏—Å–∏ (–ø—É—Å—Ç–æ–µ –§–ò–û, –ø—É—Å—Ç–∞—è –≥—Ä—É–ø–ø–∞, –Ω–µ–≤–µ—Ä–Ω—ã–π —Ç–∏–ø GPA) ‚Üí ValueError/TypeError –ø–æ —É—Å–º–æ—Ç—Ä–µ–Ω–∏—é (–æ–ø–∏—Å–∞—Ç—å –≤ –¥–æ–∫—Å—Ç—Ä–∏–Ω–≥–µ).
print(format_record(("", "ABB-01", 3.999)), "‚Üí 'ValueError'")
print(format_record(("–ü–µ—Ç—Ä–æ–≤", "ABB-01", 3.999)), "‚Üí 'ValueError'")
print(format_record(("–ü–µ—Ç—Ä–æ–≤ –ü—ë—Ç—Ä", "", 5.0)), "‚Üí 'ValueError'")
print(format_record(("–ü–µ—Ç—Ä–æ–≤ –ü—ë—Ç—Ä", "IKBO-12", 5)), "‚Üí 'TypeError'")
```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 1](./images/lab02/03_tuples.png)


## –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 3


### –ó–∞–¥–∞–Ω–∏–µ 1
```python
def normalize(text: str, *, casefold: bool = True, yo2e: bool = True) -> str:
    
    if yo2e:
        for i in range(len(text)):
            if text[i] == "—ë":
                text = text[:i]+"–µ"+text[i+1:]
            elif text[i] == "–Å":
                text = text[:i]+"–ï"+text[i+1:]
    if casefold:
        text = text.casefold()
    
    text = " ".join(text.split())
    return text

# –ï—Å–ª–∏ casefold=True ‚Äî –ø—Ä–∏–≤–µ—Å—Ç–∏ –∫ casefold (–ª—É—á—à–µ, —á–µ–º lower –¥–ª—è –Æ–Ω–∏–∫–æ–¥–∞).
# –ï—Å–ª–∏ yo2e=True ‚Äî –∑–∞–º–µ–Ω–∏—Ç—å –≤—Å–µ —ë/–Å –Ω–∞ –µ/–ï.
# –£–±—Ä–∞—Ç—å –Ω–µ–≤–∏–¥–∏–º—ã–µ —É–ø—Ä–∞–≤–ª—è—é—â–∏–µ —Å–∏–º–≤–æ–ª—ã (–Ω–∞–ø—Ä–∏–º–µ—Ä, \t, \r) ‚Üí –∑–∞–º–µ–Ω–∏—Ç—å –Ω–∞ –ø—Ä–æ–±–µ–ª—ã, —Å—Ö–ª–æ–ø–Ω—É—Ç—å –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è –ø—Ä–æ–±–µ–ª—ã –≤ –æ–¥–∏–Ω.

import re

def tokenize(text: str) -> list[str]:
    g = ''
    # h = 0
    for i in range(len(text)):
        # if h == 1:
        #     h = 0
        #     continue
        if text[i]+"g" == "\g":
            text = text[:i]+"  "+text[i+2:]
            # h=1
        elif not(re.fullmatch(r"[\w-]", text[i])):
            text = text[:i]+" "+text[i+1:]
    text = text.split()
    return text


# –†–∞–∑–±–∏—Ç—å –Ω–∞ ¬´—Å–ª–æ–≤–∞¬ª –ø–æ –Ω–µ–±—É–∫–≤–µ–Ω–Ω–æ-—Ü–∏—Ñ—Ä–æ–≤—ã–º —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—è–º.
# –í –∫–∞—á–µ—Å—Ç–≤–µ —Å–ª–æ–≤–∞ —Å—á–∏—Ç–∞–µ–º –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Å–∏–º–≤–æ–ª–æ–≤ \w (–±—É–∫–≤—ã/—Ü–∏—Ñ—Ä—ã/–ø–æ–¥—á—ë—Ä–∫–∏–≤–∞–Ω–∏–µ) –ø–ª—é—Å –¥–µ—Ñ–∏—Å –≤–Ω—É—Ç—Ä–∏ —Å–ª–æ–≤–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –ø–æ-–Ω–∞—Å—Ç–æ—è—â–µ–º—É).
# –ß–∏—Å–ª–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, 2025) —Å—á–∏—Ç–∞–µ–º —Å–ª–æ–≤–∞–º–∏.

def count_freq(tokens: list[str]) -> dict[str, int]:
    freq: dict[str, int] = {}
    for t in tokens:
        if t in freq:
            freq[t.replace("—ë","–µ")] += 1
        else:
            freq[t.replace("—ë","–µ")] = 1
    return dict(sorted(freq.items()))


def top_n(freq: dict[str, int], n: int = 5) -> list[tuple[str, int]]:
    pairs: list[tuple[int, str]] = []
    for w, c in freq.items():
        pairs.append((-c, w))  
    pairs.sort() 
    result: list[tuple[str, int]] = []
    i = 0
    for c, w in pairs:
        if i >= n:
            break
        result.append((w, -c))
        i += 1
    return result


# –í–µ—Ä–Ω—É—Ç—å —Ç–æ–ø-N –ø–æ —É–±—ã–≤–∞–Ω–∏—é —á–∞—Å—Ç–æ—Ç—ã; –ø—Ä–∏ —Ä–∞–≤–µ–Ω—Å—Ç–≤–µ ‚Äî –ø–æ –∞–ª—Ñ–∞–≤–∏—Ç—É —Å–ª–æ–≤–∞.
```


### –ó–∞–¥–∞–Ω–∏–µ 2
```python
from ..lib.text import normalize, tokenize, count_freq, top_n

# normalize
assert normalize("–ü—Ä–ò–≤–ï—Ç\n–ú–ò—Ä\t") == "–ø—Ä–∏–≤–µ—Ç –º–∏—Ä"
assert normalize("—ë–∂–∏–∫, –Å–ª–∫–∞") == "–µ–∂–∏–∫, –µ–ª–∫–∞"

# tokenize
assert tokenize("–ø—Ä–∏–≤–µ—Ç, –º–∏—Ä!") == ["–ø—Ä–∏–≤–µ—Ç", "–º–∏—Ä"]
assert tokenize("–ø–æ-–Ω–∞—Å—Ç–æ—è—â–µ–º—É –∫—Ä—É—Ç–æ") == ["–ø–æ-–Ω–∞—Å—Ç–æ—è—â–µ–º—É", "–∫—Ä—É—Ç–æ"]
assert tokenize("2025 –≥–æ–¥") == ["2025", "–≥–æ–¥"]

# count_freq + top_n
freq = count_freq(["a","b","a","c","b","a"])
assert freq == {"a":3,"b":2,"c":1}
assert top_n(freq, 2) == [("a",3), ("b",2)]

# —Ç–∞–π-–±—Ä–µ–π–∫ –ø–æ —Å–ª–æ–≤—É –ø—Ä–∏ —Ä–∞–≤–Ω–æ–π —á–∞—Å—Ç–æ—Ç–µ
freq2 = count_freq(["bb","aa","bb","aa","cc"])
assert top_n(freq2, 2) == [("aa",2), ("bb",2)]

print("OK")


# cd /home/mol/Desktop/python_labs                                      Ó™Ñ main  Ôëô Ôê† ÔÄõ    
# python -m src.lab03.test_text
```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 1](./images/lab03/test_text.png)


### –ó–∞–¥–∞–Ω–∏–µ 3
```python
# src/lab03/text_stats.py
import sys
from ..lib.text import normalize, tokenize, count_freq, top_n

def main() -> None:
    text = str(sys.stdin.read())
    # text2 = '–ü—Ä–∏–≤–µ—Ç, –º–∏—Ä! –ü—Ä–∏–≤–µ—Ç!!!\n'
    tokens = tokenize(normalize(text))
    freq = count_freq(tokens)

    print(f"–í—Å–µ–≥–æ —Å–ª–æ–≤: {len(tokens)}")
    print(f"–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤: {len(set(tokens))}")
    print("–¢–æ–ø-5:")
    for w, c in sorted(freq.items())[::-1]:
        print(f"{w}:{c}")

if __name__ == "__main__":
    main()
```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 1](./images/lab03/text_stats.png)


## –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 4

### –ó–∞–¥–∞–Ω–∏–µ 1
```python
from src.lib.text import normalize, tokenize, count_freq, top_n

from pathlib import Path

def read_text(path: str | Path, encoding: str = "utf-8") -> str:
    p = Path(path)
    # FileNotFoundError –∏ UnicodeDecodeError –ø—É—Å—Ç—å ¬´–≤—Å–ø–ª—ã–≤–∞—é—Ç¬ª ‚Äî —ç—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ
    return p.read_text(encoding=encoding)

import csv
from pathlib import Path
from typing import Iterable, Sequence

def write_csv(rows: Iterable[Sequence], path: str | Path,
              header: tuple[str, ...] | None = None) -> None:
    p = Path(path)
    rows = list(rows)
    with p.open("w", newline="", encoding="utf-8") as f:
        w = csv.writer(f)
        if header is not None:
            w.writerow(header)
        for r in rows:
            w.writerow(r)

txt = read_text("data/lab04/input.txt")  # –¥–æ–ª–∂–µ–Ω –≤–µ—Ä–Ω—É—Ç—å —Å—Ç—Ä–æ–∫—É
print(txt)
write_csv([("word","count"),("test",3)], "data/lab04/check.csv")  # —Å–æ–∑–¥–∞—Å—Ç CSV
```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 1](./images/lab04/io_txt_csv1.png)
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 2](./images/lab04/lab4_input.png)
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 3](./images/lab04/lab4_check.png)

### –ó–∞–¥–∞–Ω–∏–µ 2
```python
from src.lab04.io_txt_csv import read_text, write_csv
from ..lib.text import normalize, tokenize, count_freq, top_n


txt = read_text("data/lab04/input.txt")
if txt == "":
    print()
    op = [("word","count")]
    write_csv(op, "data/lab04/check.csv")
else:
    text = txt
    tokens = tokenize(normalize(text))
    freq = count_freq(tokens)

    print(f"–í—Å–µ–≥–æ —Å–ª–æ–≤: {len(tokens)}")
    print(f"–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤: {len(set(tokens))}")
    print("–¢–æ–ø-5:")
    op = [("word","count")]
    for w, c in top_n(freq):
        op.append((w,c))
        print(f"{w}:{c}")

    write_csv(op, "data/lab04/check.csv")
```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 1](./images/lab04/text_report.png)
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 2](./images/lab04/report_check.png)



## –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 5

### –ó–∞–¥–∞–Ω–∏–µ 1
```python
from pathlib import Path
import json
import csv
from typing import Any

# from src.lib.text import normalize, tokenize, count_freq, top_n

def json_to_csv(json_path: str | Path, csv_path: str | Path) -> None:
    p_json = Path(json_path)
    p_csv = Path(csv_path)

    # if tokenize(p_json)[-1].lower() != "json" or tokenize(p_csv)[-1].lower() != "csv":
    if p_json.suffix.lower() != ".json" or p_csv.suffix.lower() != ".csv":
        raise ValueError("–ù–µ–≤–µ—Ä–Ω—ã–π —Ç–∏–ø —Ñ–∞–π–ª–∞: –æ–∂–∏–¥–∞—é—Ç—Å—è .json (–≤—Ö–æ–¥) –∏ .csv (–≤—ã—Ö–æ–¥).")

    with p_json.open(encoding="utf-8") as jf:
        try:
            data: Any = json.load(jf)
        except json.JSONDecodeError as e:
            raise ValueError(f"–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π JSON: {e}") from e

    if not isinstance(data, list) or len(data) == 0:
        raise ValueError("–ü—É—Å—Ç–æ–π JSON –∏–ª–∏ –Ω–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ (–Ω—É–∂–µ–Ω –Ω–µ–ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫ –æ–±—ä–µ–∫—Ç–æ–≤).")

    for i, item in enumerate(data):
        if not isinstance(item, dict):
            raise ValueError(f"JSON –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å–ø–∏—Å–∫–æ–º —Å–ª–æ–≤–∞—Ä–µ–π; —ç–ª–µ–º–µ–Ω—Ç #{i} –∏–º–µ–µ—Ç —Ç–∏–ø {type(item).__name__}.")

    keys: set[str] = set()
    for obj in data:
        keys.update(obj.keys())
    fieldnames = sorted(keys)

    with p_csv.open("w", newline="", encoding="utf-8") as cf:
        writer = csv.DictWriter(cf, fieldnames=fieldnames)
        writer.writeheader()
        for obj in data:
            row = {k: obj.get(k, "") for k in fieldnames}
            writer.writerow(row)


def _sniff_dialect(sample: str) -> csv.Dialect:
    try:
        return csv.Sniffer().sniff(sample, delimiters=",;")
    except csv.Error:
        return csv.get_dialect("excel")

def csv_to_json(csv_path: str | Path, json_path: str | Path) -> None:
    p_csv = Path(csv_path)
    p_json = Path(json_path)

    if p_csv.suffix.lower() != ".csv" or p_json.suffix.lower() != ".json":
        raise ValueError("–ù–µ–≤–µ—Ä–Ω—ã–π —Ç–∏–ø —Ñ–∞–π–ª–∞: –æ–∂–∏–¥–∞—é—Ç—Å—è .csv (–≤—Ö–æ–¥) –∏ .json (–≤—ã—Ö–æ–¥).")

    with p_csv.open(encoding="utf-8") as f:
        sample = f.read(4096)
        if not sample.strip():
            raise ValueError("–ü—É—Å—Ç–æ–π CSV.")
        f.seek(0)
        dialect = _sniff_dialect(sample)
        reader = csv.DictReader(f, dialect=dialect)

        if not reader.fieldnames or all((h or "").strip() == "" for h in reader.fieldnames):
            raise ValueError("CSV –±–µ–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞.")

        rows = [{k: (v if v is not None else "") for k, v in row.items()} for row in reader]

    if len(rows) == 0:
        raise ValueError("CSV –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Å—Ç—Ä–æ–∫ –¥–∞–Ω–Ω—ã—Ö.")

    with p_json.open("w", encoding="utf-8") as jf:
        json.dump(rows, jf, ensure_ascii=False, indent=2)



json_to_csv('data/samples/people.json','data/out/people_from_json.csv')
csv_to_json('data/samples/people.csv','data/out/people_from_csv.json')
```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 1](./images/lab05/people.json.png)
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 2](./images/lab05/people_from_json.csv.png)
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 3](./images/lab05/people.csv.png)
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 4](./images/lab05/people_from_csv.json.png)



### –ó–∞–¥–∞–Ω–∏–µ 2
```python
from pathlib import Path
import csv
from openpyxl import Workbook
from openpyxl.utils import get_column_letter

def csv_to_xlsx(csv_path: str | Path, xlsx_path: str | Path) -> None:
    p_csv = Path(csv_path)
    p_xlsx = Path(xlsx_path)

    if p_csv.suffix.lower() != ".csv" or p_xlsx.suffix.lower() != ".xlsx":
        raise ValueError("–ù–µ–≤–µ—Ä–Ω—ã–π —Ç–∏–ø —Ñ–∞–π–ª–∞: –æ–∂–∏–¥–∞—é—Ç—Å—è .csv (–≤—Ö–æ–¥) –∏ .xlsx (–≤—ã—Ö–æ–¥).")

    with p_csv.open(encoding="utf-8") as f:
        sample = f.read(4096)
        if not sample.strip():
            raise ValueError("–ü—É—Å—Ç–æ–π CSV.")
        f.seek(0)
        try:
            dialect = csv.Sniffer().sniff(sample, delimiters=",;")
        except csv.Error:
            dialect = csv.get_dialect("excel")
        reader = csv.reader(f, dialect=dialect)
        rows = list(reader)

    if not rows:
        raise ValueError("CSV –ø—É—Å—Ç.")
    header = rows[0]
    if not header or all((h or "").strip() == "" for h in header):
        raise ValueError("CSV –±–µ–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞.")

    wb = Workbook()
    ws = wb.active
    ws.title = "Sheet1"

    for row in rows:
        ws.append(row)

    # –ê–≤—Ç–æ—à–∏—Ä–∏–Ω–∞ –∫–æ–ª–æ–Ω–æ–∫
    col_widths = [0] * len(header)
    for row in rows:
        for i, cell in enumerate(row):
            length = len(str(cell)) if cell is not None else 0
            if i >= len(col_widths):
                col_widths.extend([0] * (i + 1 - len(col_widths)))
            if length > col_widths[i]:
                col_widths[i] = length

    for i, width in enumerate(col_widths, start=1):
        ws.column_dimensions[get_column_letter(i)].width = max(8, width)

    wb.save(p_xlsx)

csv_to_xlsx('data/samples/people.csv','data/out/people.xlsx')
```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 1](./images/lab05/people.csv.png)
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 2](./images/lab05/people.xlsx.png)



## –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 6

### cli_text.py
```python
import argparse
from pathlib import Path
import sys

from src.lib.text import normalize, tokenize, count_freq


def main() -> None:
    parser = argparse.ArgumentParser(description="CLI-—É—Ç–∏–ª–∏—Ç—ã –ª–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–æ–π ‚Ññ6")
    subparsers = parser.add_subparsers(dest="command")

    # –ø–æ–¥–∫–æ–º–∞–Ω–¥–∞ cat
    cat_parser = subparsers.add_parser("cat", help="–í—ã–≤–µ—Å—Ç–∏ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞")
    cat_parser.add_argument("--input", required=True, help="–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É")
    cat_parser.add_argument("-n", action="store_true", help="–ù—É–º–µ—Ä–æ–≤–∞—Ç—å —Å—Ç—Ä–æ–∫–∏")

    # –ø–æ–¥–∫–æ–º–∞–Ω–¥–∞ stats
    stats_parser = subparsers.add_parser("stats", help="–ß–∞—Å—Ç–æ—Ç—ã —Å–ª–æ–≤")
    stats_parser.add_argument("--input", required=True, help="–ü—É—Ç—å –∫ —Ç–µ–∫—Å—Ç–æ–≤–æ–º—É —Ñ–∞–π–ª—É")
    stats_parser.add_argument("--top", type=int, default=5, help="–°–∫–æ–ª—å–∫–æ —Å–ª–æ–≤ –≤—ã–≤–µ—Å—Ç–∏")

    args = parser.parse_args()

    if args.command == "cat":
        path = Path(args.input)
        try:
            with path.open(encoding="utf-8") as f:
                if args.n:
                    for i, line in enumerate(f, start=1):
                        print(f"{i}\t{line.rstrip()}")
                else:
                    for line in f:
                        print(line.rstrip())
        except FileNotFoundError:
            print(f"–û—à–∏–±–∫–∞: —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {path}", file=sys.stderr)
            sys.exit(1)
    elif args.command == "stats":
        path = Path(args.input)
        try:
            text = path.read_text(encoding="utf-8")
        except FileNotFoundError:
            print(f"–û—à–∏–±–∫–∞: —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {path}", file=sys.stderr)
            sys.exit(1)

        text_norm = normalize(text)
        tokens = tokenize(text_norm)
        freqs = count_freq(tokens)

        if args.top <= 0:
            print("–û—à–∏–±–∫–∞: –∑–Ω–∞—á–µ–Ω–∏–µ --top –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å > 0", file=sys.stderr)
            sys.exit(2)

        items = sorted(freqs.items(), key=lambda kv: kv[1], reverse=True)[: args.top]
        for word, cnt in items:
            print(f"{word}\t{cnt}")
    else:
        #help
        parser.print_help()


if __name__ == "__main__":
    main()
```



### cli_convert.py
```python
import argparse
from pathlib import Path
import sys

from src.lab05.json_csv import json_to_csv, csv_to_json
from src.lab05.csv_xlsx import csv_to_xlsx


def ensure_input(path: Path) -> None:
    if not path.exists():
        print(f"–û—à–∏–±–∫–∞: –≤—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {path}", file=sys.stderr)
        sys.exit(1)


def prepare_output(path: Path) -> None:
    if path.parent:
        path.parent.mkdir(parents=True, exist_ok=True)


def main() -> None:
    parser = argparse.ArgumentParser(description="–ö–æ–Ω–≤–µ—Ä—Ç–µ—Ä—ã –¥–∞–Ω–Ω—ã—Ö")
    sub = parser.add_subparsers(dest="cmd")

    p1 = sub.add_parser("json2csv", help="–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å JSON ‚Üí CSV")
    p1.add_argument("--in", dest="input", required=True, help="–í—Ö–æ–¥–Ω–æ–π JSON-—Ñ–∞–π–ª")
    p1.add_argument("--out", dest="output", required=True, help="–í—ã—Ö–æ–¥–Ω–æ–π CSV-—Ñ–∞–π–ª")

    p2 = sub.add_parser("csv2json", help="–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å CSV ‚Üí JSON")
    p2.add_argument("--in", dest="input", required=True, help="–í—Ö–æ–¥–Ω–æ–π CSV-—Ñ–∞–π–ª")
    p2.add_argument("--out", dest="output", required=True, help="–í—ã—Ö–æ–¥–Ω–æ–π JSON-—Ñ–∞–π–ª")

    p3 = sub.add_parser("csv2xlsx", help="–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å CSV ‚Üí XLSX")
    p3.add_argument("--in", dest="input", required=True, help="–í—Ö–æ–¥–Ω–æ–π CSV-—Ñ–∞–π–ª")
    p3.add_argument("--out", dest="output", required=True, help="–í—ã—Ö–æ–¥–Ω–æ–π XLSX-—Ñ–∞–π–ª")

    args = parser.parse_args()

    if args.cmd == "json2csv":
        src = Path(args.input)
        dst = Path(args.output)
        ensure_input(src)
        prepare_output(dst)
        try:
            json_to_csv(src, dst)
        except ValueError as e:
            print(f"–û—à–∏–±–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ JSON ‚Üí CSV: {e}", file=sys.stderr)
            sys.exit(2)

    elif args.cmd == "csv2json":
        src = Path(args.input)
        dst = Path(args.output)
        ensure_input(src)
        prepare_output(dst)
        try:
            csv_to_json(src, dst)
        except ValueError as e:
            print(f"–û—à–∏–±–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ CSV ‚Üí JSON: {e}", file=sys.stderr)
            sys.exit(2)

    elif args.cmd == "csv2xlsx":
        src = Path(args.input)
        dst = Path(args.output)
        ensure_input(src)
        prepare_output(dst)
        try:
            csv_to_xlsx(src, dst)
        except ValueError as e:
            print(f"–û—à–∏–±–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ CSV ‚Üí XLSX: {e}", file=sys.stderr)
            sys.exit(2)

    else:
        parser.print_help()


if __name__ == "__main__":
    main()
```

### out
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 1](./images/lab06/out.png)

### cli_text
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 1](./images/lab06/cli_text.png)

### cli_convert json2csv
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 1](./images/lab06/cli_convert_json2csv.png)

### cli_convert csv2json
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 1](./images/lab06/cli_convert_csv2json.png)

### cli_convert csv2xlsx
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 1](./images/lab06/cli_convert_csv2xlsx.png)


## –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 7


### python -m venv .venv
```
python_labs ‚ùØ python -m venv .venv
source .venv/bin/activate           # Windows: .venv\Scripts\activate
python -m pip install pytest pytest-cov black

Requirement already satisfied: pytest in ./.venv/lib/python3.13/site-packages (9.0.1)
Requirement already satisfied: pytest-cov in ./.venv/lib/python3.13/site-packages (7.0.0)
Requirement already satisfied: black in ./.venv/lib/python3.13/site-packages (25.11.0)
Requirement already satisfied: iniconfig>=1.0.1 in ./.venv/lib/python3.13/site-packages (from pytest) (2.3.0)
Requirement already satisfied: packaging>=22 in ./.venv/lib/python3.13/site-packages (from pytest) (25.0)
Requirement already satisfied: pluggy<2,>=1.5 in ./.venv/lib/python3.13/site-packages (from pytest) (1.6.0)
Requirement already satisfied: pygments>=2.7.2 in ./.venv/lib/python3.13/site-packages (from pytest) (2.19.2)
Requirement already satisfied: coverage>=7.10.6 in ./.venv/lib/python3.13/site-packages (from coverage[toml]>=7.10.6->pytest-cov) (7.12.0)
Requirement already satisfied: click>=8.0.0 in ./.venv/lib/python3.13/site-packages (from black) (8.3.1)
Requirement already satisfied: mypy-extensions>=0.4.3 in ./.venv/lib/python3.13/site-packages (from black) (1.1.0)
Requirement already satisfied: pathspec>=0.9.0 in ./.venv/lib/python3.13/site-packages (from black) (0.12.1)
Requirement already satisfied: platformdirs>=2 in ./.venv/lib/python3.13/site-packages (from black) (4.5.0)
Requirement already satisfied: pytokens>=0.3.0 in ./.venv/lib/python3.13/site-packages (from black) (0.3.0)
```

### pytest -ra
```
python_labs ‚ùØ pytest -ra

================================================================================= test session starts ==================================================================================
platform linux -- Python 3.13.7, pytest-9.0.1, pluggy-1.6.0
rootdir: /home/mol/Desktop/python_labs
configfile: pyproject.toml
testpaths: tests
plugins: cov-7.0.0
collected 24 items                                                                                                                                                                     

tests/test_json_csv.py ..........                                                                                                                                                [ 41%]
tests/test_text.py ..............                                                                                                                                                [100%]

================================================================================== 24 passed in 0.05s ==================================================================================
```

### black --check .
```
python_labs ‚ùØ black --check .
No Python files are present to be formatted. Nothing to do üò¥
```

### pytest --cov=src --cov-report=term-missing
```
python_labs ‚ùØ pytest --cov=src --cov-report=term-missing  
================================================================================= test session starts ==================================================================================
platform linux -- Python 3.13.7, pytest-9.0.1, pluggy-1.6.0
rootdir: /home/mol/Desktop/python_labs
configfile: pyproject.toml
testpaths: tests
plugins: cov-7.0.0
collected 24 items                                                                                                                                                                     

tests/test_json_csv.py ..........                                                                                                                                                [ 41%]
tests/test_text.py ..............                                                                                                                                                [100%]

==================================================================================== tests coverage ====================================================================================
___________________________________________________________________ coverage: platform linux, python 3.13.7-final-0 ____________________________________________________________________

Name                       Stmts   Miss  Cover   Missing
--------------------------------------------------------
src/lab05/__init__.py          0      0   100%
src/lab05/csv_xlsx.py         42     42     0%   1-53
src/lab05/json_csv.py         56      6    89%   30, 50-51, 75, 82-83
src/lab06/__init__.py          0      0   100%
src/lab06/cli_convert.py      58     58     0%   1-76
src/lab06/cli_text.py         45     45     0%   1-62
src/lib/text.py               40      1    98%   31
--------------------------------------------------------
TOTAL                        241    152    37%
================================================================================== 24 passed in 0.10s ==================================================================================
```


## –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 8


### python -m src.lab08.models
``` python

```



















